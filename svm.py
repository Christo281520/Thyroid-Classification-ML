# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lBJjqY4dVrYJRyBybGONoVGcpnJuljrV
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_selection import mutual_info_classif
from sklearn.svm import SVC

df = pd.read_csv("https://raw.githubusercontent.com/Christo2810/ds-and-ml/refs/heads/main/balanced_thyroid_dataset%20(1).csv")

print(df.head())
print(df.info())
print(df.describe())

print("\nMissing Values:\n", df.isnull().sum())

X = df.drop(columns=['Category'])
y = df['Category']

scale_cols = ['TSH Measured', 'Tumor']
scaler = StandardScaler()
X[scale_cols] = scaler.fit_transform(X[scale_cols])

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)

mutual_info = mutual_info_classif(X_train, y_train)
feature_scores = pd.DataFrame({
    'Feature': X_train.columns,
    'Mutual Info': mutual_info
}).sort_values(by='Mutual Info', ascending=False)

selected_features = feature_scores['Feature'].head(10).tolist()
print("\nSelected Features:", selected_features)

plt.figure(figsize=(10,6))
plt.barh(feature_scores['Feature'], feature_scores['Mutual Info'])
plt.title("Feature Importance (Mutual Info)")
plt.show()

X_train_clean = X_train[selected_features].copy()

for f in selected_features:
    Q1 = X_train_clean[f].quantile(0.25)
    Q3 = X_train_clean[f].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    mask = (X_train_clean[f] >= lower) & (X_train_clean[f] <= upper)
    X_train_clean = X_train_clean[mask]

y_train_clean = y_train.loc[X_train_clean.index]

print("\nTraining Data After Outlier Cleaning:", X_train_clean.shape)

kernels = ['linear', 'poly', 'rbf', 'sigmoid']
results = {}

for kernel in kernels:
    print(f"\nTraining SVM with kernel: {kernel}")
    svm_model = SVC(kernel=kernel, gamma='scale')
    svm_model.fit(X_train_clean, y_train_clean)

    y_pred = svm_model.predict(X_test[selected_features])
    acc = accuracy_score(y_test, y_pred)
    results[kernel] = (acc, y_pred)

print("\n Accuracy for All SVM Kernels:\n")
for k, v in results.items():
    print(f"{k}: {v[0]:.4f}")

best_kernel = max(results, key=lambda k: results[k][0])
best_accuracy, best_pred = results[best_kernel]

print(f"\n Best Kernel: {best_kernel} (Accuracy = {best_accuracy:.4f})")

print("\nClassification Report:\n")
print(classification_report(y_test, best_pred, zero_division=1))

cm = confusion_matrix(y_test, best_pred)
sns.heatmap(cm, annot=True, cmap="Blues", fmt='d')
plt.title(f"SVM Confusion Matrix ({best_kernel} kernel)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()